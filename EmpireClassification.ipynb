{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9cf46f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC as SupportVectorClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LSTM, Concatenate, Embedding, Input, Bidirectional, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from collections import deque, Counter\n",
    "from itertools import permutations, repeat, combinations\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0429344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "empires = []\n",
    "vectorizer = CountVectorizer()\n",
    "min_sentence_length = 5\n",
    "level_sample_sizes = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "82d4217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Resources/Data/EmpireText.txt\", \"r\", encoding=\"utf8\") as file:\n",
    "    line = file.readline().replace(\"\\n\", \"\").split(\" \")\n",
    "    for empire in line:\n",
    "        empires.append(empire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e6852b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "labels = []\n",
    "with open(\"Resources/Data/EmpireText.txt\", \"r\", encoding=\"utf8\") as file: \n",
    "    for line in file.readlines()[1:]:\n",
    "        line = line.strip().replace(\"\\n\", \"\")\n",
    "        line = re.sub(\"\\[.{0,4}]\", \"\", line) #remove wikipedia citings\n",
    "\n",
    "\n",
    "        if line in empires:\n",
    "            current_empire = line\n",
    "            continue\n",
    "        elif len(line.replace(\" \", \"\")) < 15:\n",
    "            continue\n",
    "        elif line[-1] != \".\":\n",
    "            line += \".\"\n",
    "    \n",
    "        line = nltk.sent_tokenize(line)\n",
    "        for sentence in line:\n",
    "            text.append(sentence)\n",
    "            labels.append(current_empire)\n",
    "            \n",
    "data = pd.DataFrame({\"label\":labels, \"text\":text})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769e0173",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32657aad",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a3519ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Roman</td>\n",
       "      <td>The Roman Empire, the ancient empire, centred ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>The Spanish Empire (Spanish: Imperio español),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Russian</td>\n",
       "      <td>The Russian Empire, also known as Imperial Rus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roman</td>\n",
       "      <td>A period of unrest and civil wars in the 1st c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Roman</td>\n",
       "      <td>This period encompassed the career of Julius C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0    Roman  The Roman Empire, the ancient empire, centred ...\n",
       "1  Spanish  The Spanish Empire (Spanish: Imperio español),...\n",
       "2  Russian  The Russian Empire, also known as Imperial Rus...\n",
       "3    Roman  A period of unrest and civil wars in the 1st c...\n",
       "4    Roman  This period encompassed the career of Julius C..."
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e2a2a062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3238 entries, 0 to 3237\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   3238 non-null   object\n",
      " 1   text    3238 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 50.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Roman      1308\n",
       "Russian     993\n",
       "Spanish     937\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_value_counts = data[\"label\"].value_counts()\n",
    "training_value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465d156b",
   "metadata": {},
   "source": [
    "# Text classification:\n",
    "### The process of text classification is comprised of 4 main steps\n",
    "#### - Preprocessing the text\n",
    "#### - Encoding labels\n",
    "#### - Vectorizing the text\n",
    "#### - Training the model(s)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b562a889",
   "metadata": {},
   "source": [
    "## Text preprocessing\n",
    "### Steps:\n",
    "- Lowercasing\n",
    "- Tokenization\n",
    "- POS tagging\n",
    "- Lemmatization\n",
    "\n",
    "Note: When tested, the models showed better results without the removal of stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96bdb28",
   "metadata": {},
   "source": [
    "### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "599815ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish empire:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Spanish Empire (Spanish: Imperio español), also known as the Hispanic Monarchy (Spanish: Monarquía Hispánica) or the Catholic Monarchy (Spanish: Monarquía Católica) was a colonial empire governed by Spain and its predecessor states between 1492 and 1976.'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_paragraph = data['text'][1]\n",
    "example_paragraph = \"\".join(example_paragraph)\n",
    "print(data['label'][1], \"empire:\")\n",
    "example_paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b2fc66e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the spanish empire (spanish: imperio español), also known as the hispanic monarchy (spanish: monarquía hispánica) or the catholic monarchy (spanish: monarquía católica) was a colonial empire governed by spain and its predecessor states between 1492 and 1976.'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowercase_paragraph = example_paragraph.lower()\n",
    "lowercase_paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "dfccf56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'the', 'spanish', 'empire', '(', 'spanish', ':', 'imperio', 'español', ')', ',', 'also', 'known', 'as', 'the', 'hispanic', 'monarchy', '(', 'spanish', ':', 'monarquía', 'hispánica', ')', 'or', 'the', 'catholic', 'monarchy', '(', 'spanish', ':', 'monarquía', 'católica', ')', 'was', 'a', 'colonial', 'empire', 'governed', 'by', 'spain', 'and', 'its', 'predecessor', 'states', 'between', '1492', 'and', '1976', '.', "
     ]
    }
   ],
   "source": [
    "tokenized_paragraph = nltk.word_tokenize(lowercase_paragraph)\n",
    "for word in tokenized_paragraph:\n",
    "    print(f\"'{word}'\", end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "48bd2b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the', 'DT'), ('spanish', 'JJ'), ('empire', 'NN'), ('(', '('), ('spanish', 'JJ'), (':', ':'), ('imperio', 'NN'), ('español', 'NN'), (')', ')'), (',', ','), ('also', 'RB'), ('known', 'VBN'), ('as', 'IN'), ('the', 'DT'), ('hispanic', 'JJ'), ('monarchy', 'NN'), ('(', '('), ('spanish', 'JJ'), (':', ':'), ('monarquía', 'NN'), ('hispánica', 'NN'), (')', ')'), ('or', 'CC'), ('the', 'DT'), ('catholic', 'JJ'), ('monarchy', 'NN'), ('(', '('), ('spanish', 'JJ'), (':', ':'), ('monarquía', 'NN'), ('católica', 'NN'), (')', ')'), ('was', 'VBD'), ('a', 'DT'), ('colonial', 'JJ'), ('empire', 'NN'), ('governed', 'VBN'), ('by', 'IN'), ('spain', 'NN'), ('and', 'CC'), ('its', 'PRP$'), ('predecessor', 'NN'), ('states', 'NNS'), ('between', 'IN'), ('1492', 'CD'), ('and', 'CC'), ('1976', 'CD'), ('.', '.'), "
     ]
    }
   ],
   "source": [
    "tagged_paragraph = nltk.pos_tag(tokenized_paragraph)\n",
    "for word in tagged_paragraph:\n",
    "    print(word, end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "41ddf9c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'the', 'spanish', 'empire', '(', 'spanish', ':', 'imperio', 'español', ')', ',', 'also', 'know', 'a', 'the', 'hispanic', 'monarchy', '(', 'spanish', ':', 'monarquía', 'hispánica', ')', 'or', 'the', 'catholic', 'monarchy', '(', 'spanish', ':', 'monarquía', 'católica', ')', 'be', 'a', 'colonial', 'empire', 'govern', 'by', 'spain', 'and', 'it', 'predecessor', 'state', 'between', '1492', 'and', '1976', '.', "
     ]
    }
   ],
   "source": [
    "def get_pos(tag):    \n",
    "    if tag.startswith('J'):\n",
    "        return nltk.corpus.wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return nltk.corpus.wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return nltk.corpus.wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return nltk.corpus.wordnet.ADV\n",
    "    else:\n",
    "        return nltk.corpus.wordnet.NOUN\n",
    "        \n",
    "wnl = WordNetLemmatizer()\n",
    "lemmatized_sentence = [wnl.lemmatize(word, get_pos(pos)) for word, pos in tagged_paragraph]\n",
    "for word in lemmatized_sentence:\n",
    "    print(f\"'{word}'\", end=\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0931ffa2",
   "metadata": {},
   "source": [
    "### Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3e009df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "labels = []\n",
    "wnl = WordNetLemmatizer()\n",
    "for row in data.iterrows():\n",
    "    label = row[1]['label']\n",
    "    text = row[1]['text']\n",
    "    text = nltk.word_tokenize(text)\n",
    "    text = nltk.pos_tag(text)\n",
    "    text = [wnl.lemmatize(word, get_pos(pos)) for word, pos in text]\n",
    "    sentences.append(text)\n",
    "    labels.append(label)\n",
    "\n",
    "preprocessed_data = pd.DataFrame({\"label\":labels, \"text\":sentences})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6fc53e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Roman</td>\n",
       "      <td>[The, Roman, Empire, ,, the, ancient, empire, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>[The, Spanish, Empire, (, Spanish, :, Imperio,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Russian</td>\n",
       "      <td>[The, Russian, Empire, ,, also, know, a, Imper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roman</td>\n",
       "      <td>[A, period, of, unrest, and, civil, war, in, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Roman</td>\n",
       "      <td>[This, period, encompass, the, career, of, Jul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0    Roman  [The, Roman, Empire, ,, the, ancient, empire, ...\n",
       "1  Spanish  [The, Spanish, Empire, (, Spanish, :, Imperio,...\n",
       "2  Russian  [The, Russian, Empire, ,, also, know, a, Imper...\n",
       "3    Roman  [A, period, of, unrest, and, civil, war, in, t...\n",
       "4    Roman  [This, period, encompass, the, career, of, Jul..."
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a16fa89",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5f74b9b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "for label in preprocessed_data['label']:\n",
    "    labels.append(empires.index(label))\n",
    "preprocessed_data['label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7f1fcf2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[The, Roman, Empire, ,, the, ancient, empire, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[The, Spanish, Empire, (, Spanish, :, Imperio,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[The, Russian, Empire, ,, also, know, a, Imper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[A, period, of, unrest, and, civil, war, in, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[This, period, encompass, the, career, of, Jul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  [The, Roman, Empire, ,, the, ancient, empire, ...\n",
       "1      1  [The, Spanish, Empire, (, Spanish, :, Imperio,...\n",
       "2      2  [The, Russian, Empire, ,, also, know, a, Imper...\n",
       "3      0  [A, period, of, unrest, and, civil, war, in, t...\n",
       "4      0  [This, period, encompass, the, career, of, Jul..."
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1e3cca",
   "metadata": {},
   "source": [
    "## Evening training data\n",
    "Data with varied distribution will perform worse unless accounted for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "617b4f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    937\n",
       "2    937\n",
       "1    937\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = Counter(preprocessed_data[\"label\"])\n",
    "max_len = min(label_counts.values())\n",
    "training_data = preprocessed_data.sample(frac=1).groupby('label').head(max_len)\n",
    "labels = training_data['label']\n",
    "text = training_data['text']\n",
    "value_counts = training_data['label'].value_counts()\n",
    "value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09743410",
   "metadata": {},
   "source": [
    "## Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f925ebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "text = []\n",
    "for sentence in preprocessed_data['text']:\n",
    "    text.append(\" \".join(sentence))\n",
    "vectorizer.fit(text)\n",
    "vectorized_text = vectorizer.transform(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5502c356",
   "metadata": {},
   "source": [
    "## Training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f08fa455",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques = set()\n",
    "for sentence in data['text']:\n",
    "    for word in sentence:\n",
    "        uniques.add(word)\n",
    "num_uniques = len(uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0af671e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = vectorized_text\n",
    "labels = preprocessed_data['label']\n",
    "x_train, x_test, y_train, y_test = train_test_split(text, labels, train_size=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0097ae",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a962d610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.808641975308642"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=2, max_depth=150, max_features=1000)\n",
    "decision_tree.fit(x_train, y_train)\n",
    "decision_tree_score = decision_tree.score(x_test, y_test)\n",
    "decision_tree_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e782ac3b",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c0847116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8765432098765432"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(random_state=0, n_estimators=300, max_depth=150, max_features=1000)\n",
    "random_forest.fit(x_train, y_train)\n",
    "random_forest_score = random_forest.score(x_test, y_test)\n",
    "random_forest_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a032c1",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "b9251f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8981481481481481"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_c = 0.1\n",
    "best_kernel = \"linear\"\n",
    "support_vector_machine = SupportVectorClassifier(kernel=best_kernel, C=best_c)\n",
    "support_vector_machine.fit(x_train, y_train)\n",
    "support_vector_machine_score = support_vector_machine.score(x_test, y_test)\n",
    "support_vector_machine_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2560e5",
   "metadata": {},
   "source": [
    "### Long Short Term Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b8895a",
   "metadata": {},
   "source": [
    "Sidenote: while one could convert x_Train from SparseTensor to array it causes the lstm model to have low accuracy and take 20 min per epoch, so its better to just format the data with tensorflow methods to convert it to a format that tensorflow is better equipped to handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5b8cc854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input example: [ 50  53  25  60 114  11  71  11  21  59  29   5  68  29 103 112  75  40\n",
      "   1 112  22  39  10 111  46 111  76  76  25  55  56  45  69  25  19   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0]\n",
      "label example: [1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "text = preprocessed_data['text']\n",
    "labels = preprocessed_data['label']\n",
    "longest_sentence = max(text, key=lambda x: len(x))\n",
    "encoded_sentences = [one_hot(\" \".join(sentence), num_uniques) for sentence in text]\n",
    "padded_sequences = pad_sequences(encoded_sentences, maxlen=len(longest_sentence), padding='post')\n",
    "\n",
    "def encode_labels(labels):\n",
    "    output = []\n",
    "    for label in labels:\n",
    "        label_array = np.zeros(len(empires))\n",
    "        label_array[label] = 1    \n",
    "        output.append(label_array)\n",
    "    return output\n",
    "\n",
    "labels = encode_labels(labels)\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=.1, random_state=85)\n",
    "print(\"input example:\", x_train[0])\n",
    "print(\"label example:\", y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ca1dcc00",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, None, 32)          3744      \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 200)              106400    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 256)               51456     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 194,883\n",
      "Trainable params: 194,883\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = Sequential()\n",
    "lstm.add(Embedding(num_uniques, 32))\n",
    "lstm.add(Bidirectional(LSTM(100)))\n",
    "lstm.add(Dense(256, activation=\"relu\"))\n",
    "lstm.add(Dropout(0.5))\n",
    "lstm.add(Dense(128))\n",
    "lstm.add(Dense(3, activation=\"sigmoid\"))\n",
    "optimizer = Adam(learning_rate=0.03)\n",
    "lstm.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "lstm.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "7de356a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    }
   ],
   "source": [
    "lstm.fit(np.array(x_train), np.array(y_train), epochs=60, verbose=1, batch_size=32, callbacks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a980155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 11ms/step - loss: 0.0246 - accuracy: 0.9938\n",
      "Test accuracy: 99.38271641731262\n"
     ]
    }
   ],
   "source": [
    "lstm_score = lstm.evaluate(x_test, np.array(y_test), verbose=1)\n",
    "lstm_acc = lstm_score[1]*100\n",
    "print(f'Test accuracy: {lstm_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "506c7cd5f11c76d07d3fb12eb0803be97b690f1666932904271a8a04a8fd81e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
