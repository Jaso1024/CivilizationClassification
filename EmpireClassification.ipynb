{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "9cf46f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC as SupportVectorClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LSTM, Concatenate, Embedding, Input, Bidirectional, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow_addons.activations import mish\n",
    "\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import contractions\n",
    "\n",
    "from collections import deque, Counter\n",
    "from itertools import permutations, repeat, combinations\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "0429344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "empires = []\n",
    "vectorizer = CountVectorizer()\n",
    "min_sentence_length = 7 # average length of a sentence is between 15 and 20 words\n",
    "level_sample_sizes = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "82d4217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Resources/Data/EmpireText.txt\", \"r\", encoding=\"utf8\") as file:\n",
    "    line = file.readline().replace(\"\\n\", \"\").split(\" \")\n",
    "    for empire in line:\n",
    "        empires.append(empire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "e6852b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sentence(sentence, current_empire):\n",
    "        if len(sentence.split(\" \")) > min_sentence_length:\n",
    "            sentence = contractions.fix(sentence)\n",
    "            contains_other_empire = False\n",
    "            for empire in empires:\n",
    "                if empire == current_empire:\n",
    "                    continue\n",
    "                elif re.search(empire.lower(), sentence.lower()) is not None:\n",
    "                    contains_other_empire = True\n",
    "\n",
    "            if not contains_other_empire:\n",
    "                return sentence.strip()\n",
    "\n",
    "text = []\n",
    "labels = []\n",
    "with open(\"Resources/Data/EmpireText.txt\", \"r\", encoding=\"utf8\") as file: \n",
    "    for line in file.readlines()[1:]:\n",
    "        line = line.strip().replace(\"\\n\", \"\")\n",
    "        line = re.sub(\"\\[.{0,4}]\", \"\", line) #remove wikipedia citings\n",
    "        line = line.replace(\"C.\", \"C\")\n",
    "        line = line.replace(\"E.\", \"E\")\n",
    "        line = line.replace(\"D.\", \"D\")\n",
    "        \n",
    "        if line in empires:\n",
    "            current_empire = line\n",
    "            continue\n",
    "        elif len(line.replace(\" \", \"\")) < min_sentence_length:\n",
    "            continue\n",
    "        elif len(line.split(\" \")) < min_sentence_length:\n",
    "            continue\n",
    "        elif line[-1] != \".\":\n",
    "            line += \".\"\n",
    "    \n",
    "        line = nltk.sent_tokenize(line)\n",
    "        formatted_line = \"\"\n",
    "        for sentence in line:\n",
    "            sentence = format_sentence(sentence, current_empire)\n",
    "            if sentence is not None:\n",
    "                formatted_line += sentence + \" \"\n",
    "        text.append(formatted_line)\n",
    "        labels.append(current_empire)\n",
    "            \n",
    "data = pd.DataFrame({\"label\":labels, \"text\":text})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769e0173",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32657aad",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "a3519ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Roman</td>\n",
       "      <td>The Roman Empire, the ancient empire, centred ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>The Spanish Empire (Spanish: Imperio españold)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Russian</td>\n",
       "      <td>The Russian Empire, also known as Imperial Rus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roman</td>\n",
       "      <td>A period of unrest and civil wars in the 1st c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Roman</td>\n",
       "      <td>Augustus established a form of government know...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0    Roman  The Roman Empire, the ancient empire, centred ...\n",
       "1  Spanish  The Spanish Empire (Spanish: Imperio españold)...\n",
       "2  Russian  The Russian Empire, also known as Imperial Rus...\n",
       "3    Roman  A period of unrest and civil wars in the 1st c...\n",
       "4    Roman  Augustus established a form of government know..."
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "e2a2a062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 679 entries, 0 to 678\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   679 non-null    object\n",
      " 1   text    679 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 10.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Roman      319\n",
       "Spanish    227\n",
       "Russian    133\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 674,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_value_counts = data[\"label\"].value_counts()\n",
    "training_value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465d156b",
   "metadata": {},
   "source": [
    "# Text classification:\n",
    "### The process of text classification is comprised of 4 main steps\n",
    "#### - Preprocessing the text\n",
    "#### - Encoding labels\n",
    "#### - Vectorizing the text\n",
    "#### - Training the model(s)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b562a889",
   "metadata": {},
   "source": [
    "## Text preprocessing\n",
    "### Steps:\n",
    "- Lowercasing\n",
    "- Tokenization\n",
    "- POS tagging\n",
    "- Lemmatization\n",
    "\n",
    "Note: When tested, the models showed better results without the removal of stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96bdb28",
   "metadata": {},
   "source": [
    "### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "599815ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish empire:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Spanish Empire (Spanish: Imperio españold), also known as the Hispanic Monarchy (Spanish: Monarquía Hispánica) or the Catholic Monarchy (Spanish: Monarquía Católica) was a colonial empire governed by Spain and its predecessor states between 1492 and 1976. '"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_paragraph = data['text'][1]\n",
    "example_paragraph = \"\".join(example_paragraph)\n",
    "print(data['label'][1], \"empire:\")\n",
    "example_paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "b2fc66e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the spanish empire (spanish: imperio españold), also known as the hispanic monarchy (spanish: monarquía hispánica) or the catholic monarchy (spanish: monarquía católica) was a colonial empire governed by spain and its predecessor states between 1492 and 1976. '"
      ]
     },
     "execution_count": 676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowercase_paragraph = example_paragraph.lower()\n",
    "lowercase_paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "dfccf56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'the', 'spanish', 'empire', '(', 'spanish', ':', 'imperio', 'españold', ')', ',', 'also', 'known', 'as', 'the', 'hispanic', 'monarchy', '(', 'spanish', ':', 'monarquía', 'hispánica', ')', 'or', 'the', 'catholic', 'monarchy', '(', 'spanish', ':', 'monarquía', 'católica', ')', 'was', 'a', 'colonial', 'empire', 'governed', 'by', 'spain', 'and', 'its', 'predecessor', 'states', 'between', '1492', 'and', '1976', '.', "
     ]
    }
   ],
   "source": [
    "tokenized_paragraph = nltk.word_tokenize(lowercase_paragraph)\n",
    "for word in tokenized_paragraph:\n",
    "    print(f\"'{word}'\", end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "48bd2b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the', 'DT'), ('spanish', 'JJ'), ('empire', 'NN'), ('(', '('), ('spanish', 'JJ'), (':', ':'), ('imperio', 'NN'), ('españold', 'NN'), (')', ')'), (',', ','), ('also', 'RB'), ('known', 'VBN'), ('as', 'IN'), ('the', 'DT'), ('hispanic', 'JJ'), ('monarchy', 'NN'), ('(', '('), ('spanish', 'JJ'), (':', ':'), ('monarquía', 'NN'), ('hispánica', 'NN'), (')', ')'), ('or', 'CC'), ('the', 'DT'), ('catholic', 'JJ'), ('monarchy', 'NN'), ('(', '('), ('spanish', 'JJ'), (':', ':'), ('monarquía', 'NN'), ('católica', 'NN'), (')', ')'), ('was', 'VBD'), ('a', 'DT'), ('colonial', 'JJ'), ('empire', 'NN'), ('governed', 'VBN'), ('by', 'IN'), ('spain', 'NN'), ('and', 'CC'), ('its', 'PRP$'), ('predecessor', 'NN'), ('states', 'NNS'), ('between', 'IN'), ('1492', 'CD'), ('and', 'CC'), ('1976', 'CD'), ('.', '.'), "
     ]
    }
   ],
   "source": [
    "tagged_paragraph = nltk.pos_tag(tokenized_paragraph)\n",
    "for word in tagged_paragraph:\n",
    "    print(word, end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "41ddf9c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'the', 'spanish', 'empire', '(', 'spanish', ':', 'imperio', 'españold', ')', ',', 'also', 'know', 'a', 'the', 'hispanic', 'monarchy', '(', 'spanish', ':', 'monarquía', 'hispánica', ')', 'or', 'the', 'catholic', 'monarchy', '(', 'spanish', ':', 'monarquía', 'católica', ')', 'be', 'a', 'colonial', 'empire', 'govern', 'by', 'spain', 'and', 'it', 'predecessor', 'state', 'between', '1492', 'and', '1976', '.', "
     ]
    }
   ],
   "source": [
    "def get_pos(tag):    \n",
    "    if tag.startswith('J'):\n",
    "        return nltk.corpus.wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return nltk.corpus.wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return nltk.corpus.wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return nltk.corpus.wordnet.ADV\n",
    "    else:\n",
    "        return nltk.corpus.wordnet.NOUN\n",
    "        \n",
    "wnl = WordNetLemmatizer()\n",
    "lemmatized_sentence = [wnl.lemmatize(word, get_pos(pos)) for word, pos in tagged_paragraph]\n",
    "for word in lemmatized_sentence:\n",
    "    print(f\"'{word}'\", end=\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0931ffa2",
   "metadata": {},
   "source": [
    "### Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "3e009df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "labels = []\n",
    "wnl = WordNetLemmatizer()\n",
    "for row in data.iterrows():\n",
    "    label = row[1]['label']\n",
    "    text = row[1]['text']\n",
    "    text = nltk.word_tokenize(text)\n",
    "    text = nltk.pos_tag(text)\n",
    "    text = [wnl.lemmatize(word, get_pos(pos)) for word, pos in text]\n",
    "    sentences.append(text)\n",
    "    labels.append(label)\n",
    "\n",
    "preprocessed_data = pd.DataFrame({\"label\":labels, \"text\":sentences})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "6fc53e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Roman</td>\n",
       "      <td>[The, Roman, Empire, ,, the, ancient, empire, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>[The, Spanish, Empire, (, Spanish, :, Imperio,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Russian</td>\n",
       "      <td>[The, Russian, Empire, ,, also, know, a, Imper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roman</td>\n",
       "      <td>[A, period, of, unrest, and, civil, war, in, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Roman</td>\n",
       "      <td>[Augustus, establish, a, form, of, government,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0    Roman  [The, Roman, Empire, ,, the, ancient, empire, ...\n",
       "1  Spanish  [The, Spanish, Empire, (, Spanish, :, Imperio,...\n",
       "2  Russian  [The, Russian, Empire, ,, also, know, a, Imper...\n",
       "3    Roman  [A, period, of, unrest, and, civil, war, in, t...\n",
       "4    Roman  [Augustus, establish, a, form, of, government,..."
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a16fa89",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "5f74b9b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "for label in preprocessed_data['label']:\n",
    "    labels.append(empires.index(label))\n",
    "preprocessed_data['label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "7f1fcf2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[The, Roman, Empire, ,, the, ancient, empire, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[The, Spanish, Empire, (, Spanish, :, Imperio,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[The, Russian, Empire, ,, also, know, a, Imper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[A, period, of, unrest, and, civil, war, in, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[Augustus, establish, a, form, of, government,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  [The, Roman, Empire, ,, the, ancient, empire, ...\n",
       "1      1  [The, Spanish, Empire, (, Spanish, :, Imperio,...\n",
       "2      2  [The, Russian, Empire, ,, also, know, a, Imper...\n",
       "3      0  [A, period, of, unrest, and, civil, war, in, t...\n",
       "4      0  [Augustus, establish, a, form, of, government,..."
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1e3cca",
   "metadata": {},
   "source": [
    "## Evening training data\n",
    "Data with varied distribution will perform worse unless accounted for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "617b4f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    133\n",
       "0    133\n",
       "2    133\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = Counter(preprocessed_data[\"label\"])\n",
    "max_len = min(label_counts.values())\n",
    "training_data = preprocessed_data.sample(frac=1).groupby('label').head(max_len)\n",
    "labels = training_data['label']\n",
    "text = training_data['text']\n",
    "value_counts = training_data['label'].value_counts()\n",
    "value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09743410",
   "metadata": {},
   "source": [
    "## Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "f925ebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "text = []\n",
    "for sentence in preprocessed_data['text']:\n",
    "    text.append(\" \".join(sentence))\n",
    "vectorizer.fit(text)\n",
    "vectorized_text = vectorizer.transform(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5502c356",
   "metadata": {},
   "source": [
    "## Training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "f08fa455",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques = set()\n",
    "for sentence in data['text']:\n",
    "    for word in sentence:\n",
    "        uniques.add(word)\n",
    "num_uniques = len(uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "0af671e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = vectorized_text\n",
    "labels = preprocessed_data['label']\n",
    "x_train, x_test, y_train, y_test = train_test_split(text, labels, train_size=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0097ae",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "a962d610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8970588235294118"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=2, max_depth=150, max_features=1000)\n",
    "decision_tree.fit(x_train, y_train)\n",
    "decision_tree_score = decision_tree.score(x_test, y_test)\n",
    "decision_tree_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e782ac3b",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "c0847116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9411764705882353"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(random_state=0, n_estimators=300, max_depth=150, max_features=1000)\n",
    "random_forest.fit(x_train, y_train)\n",
    "random_forest_score = random_forest.score(x_test, y_test)\n",
    "random_forest_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a032c1",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "b9251f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9705882352941176"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_c = 0.1\n",
    "best_kernel = \"linear\"\n",
    "support_vector_machine = SupportVectorClassifier(kernel=best_kernel, C=best_c)\n",
    "support_vector_machine.fit(x_train, y_train)\n",
    "support_vector_machine_score = support_vector_machine.score(x_test, y_test)\n",
    "support_vector_machine_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2560e5",
   "metadata": {},
   "source": [
    "### Long Short Term Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b8895a",
   "metadata": {},
   "source": [
    "Sidenote: while one could convert x_Train from SparseTensor to array it causes the lstm model to have low accuracy and take 20 min per epoch, so its better to just format the data with tensorflow methods to convert it to a format that tensorflow is better equipped to handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "5b8cc854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input example: [63 53 67 ...  0  0  0]\n",
      "label example: [0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "text = preprocessed_data['text']\n",
    "labels = preprocessed_data['label']\n",
    "longest_sentence = max(text, key=lambda x: len(x))\n",
    "encoded_sentences = [one_hot(\" \".join(sentence), num_uniques) for sentence in text]\n",
    "padded_sequences = pad_sequences(encoded_sentences, maxlen=len(longest_sentence), padding='post')\n",
    "\n",
    "def encode_labels(labels):\n",
    "    output = []\n",
    "    for label in labels:\n",
    "        label_array = np.zeros(len(empires))\n",
    "        label_array[label] = 1    \n",
    "        output.append(label_array)\n",
    "    return output\n",
    "\n",
    "labels = encode_labels(labels)\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=.2, random_state=42)\n",
    "print(\"input example:\", x_train[0])\n",
    "print(\"label example:\", y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679\n"
     ]
    }
   ],
   "source": [
    "print(len(padded_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "ca1dcc00",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Lstm(Model):\n",
    "    def __init__(self, uniques) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.l1 = Embedding(uniques, 64)\n",
    "        self.l2 = Bidirectional(LSTM(16))\n",
    "        self.l3 = Dropout(0.2)\n",
    "        self.l4 = Dense(128)\n",
    "        self.l6 = Dense(3, activation=\"sigmoid\")\n",
    "    \n",
    "    def call(self, inp):\n",
    "        x = self.l1(inp)\n",
    "        x = self.l2(x)\n",
    "        x = self.l3(x)\n",
    "        x = self.l4(x)\n",
    "        x = mish(x)\n",
    "        x = self.l6(x)\n",
    "        return x\n",
    "\n",
    "lstm = Lstm(num_uniques)\n",
    "lstm.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "067a2374",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = Sequential()\n",
    "lstm.add(Embedding(num_uniques, 128))\n",
    "lstm.add(Bidirectional(LSTM(4)))\n",
    "lstm.add(Dropout(0.1))\n",
    "lstm.add(Dense(3, activation=\"sigmoid\"))\n",
    "lstm.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "id": "882c282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = Sequential()\n",
    "lstm.add(Embedding(num_uniques, 128))\n",
    "lstm.add(Bidirectional(LSTM(64)))\n",
    "lstm.add(Dense(256, activation=\"relu\"))\n",
    "lstm.add(Dropout(0.5))\n",
    "lstm.add(Dense(128))\n",
    "lstm.add(Dense(3, activation=\"sigmoid\"))\n",
    "lstm.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "id": "7de356a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "9/9 [==============================] - 8s 855ms/step - loss: 0.4173 - accuracy: 0.8361 - val_loss: 0.8890 - val_accuracy: 0.6397\n",
      "Epoch 2/5\n",
      "9/9 [==============================] - 8s 848ms/step - loss: 0.3688 - accuracy: 0.8545 - val_loss: 0.8164 - val_accuracy: 0.6250\n",
      "Epoch 3/5\n",
      "9/9 [==============================] - 8s 870ms/step - loss: 0.3329 - accuracy: 0.8711 - val_loss: 0.8583 - val_accuracy: 0.6618\n",
      "Epoch 4/5\n",
      "9/9 [==============================] - 8s 862ms/step - loss: 0.3196 - accuracy: 0.8877 - val_loss: 0.8618 - val_accuracy: 0.6691\n",
      "Epoch 5/5\n",
      "9/9 [==============================] - 8s 885ms/step - loss: 0.2870 - accuracy: 0.9024 - val_loss: 0.8608 - val_accuracy: 0.6471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26796eb7760>"
      ]
     },
     "execution_count": 708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.fit(np.array(x_train), np.array(y_train), epochs=5, verbose=1, batch_size=64, callbacks=[], validation_data=(x_test, np.array(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "id": "6a980155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 82ms/step - loss: 0.9800 - accuracy: 0.6691\n",
      "Test accuracy: 66.91176295280457\n"
     ]
    }
   ],
   "source": [
    "lstm_score = lstm.evaluate(x_test, np.array(y_test), verbose=1)\n",
    "lstm_acc = lstm_score[1]*100\n",
    "print(f'Test accuracy: {lstm_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "506c7cd5f11c76d07d3fb12eb0803be97b690f1666932904271a8a04a8fd81e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
